{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3546012b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "from characterDefinitions import getHandwritingCharacterDefinitions\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14aa745",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a6587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirs = ['t5.2019.05.08','t5.2019.11.25','t5.2019.12.09','t5.2019.12.11','t5.2019.12.18',\n",
    "            't5.2019.12.20','t5.2020.01.06','t5.2020.01.08','t5.2020.01.13','t5.2020.01.15']\n",
    "charDef = getHandwritingCharacterDefinitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e86edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = []\n",
    "all_labels = []\n",
    "for directory in dataDirs:\n",
    "    \n",
    "    mat = f'./Datasets/{directory}/singleLetters.mat'\n",
    "    data = sio.loadmat(mat)\n",
    "    ctr = 0\n",
    "    for letter in charDef['charList']:\n",
    "        t = torch.Tensor(data[f'neuralActivityCube_{letter}'])\n",
    "        qty = t.shape[0]\n",
    "        labels = torch.Tensor([ctr]*qty)\n",
    "        ctr += 1\n",
    "#         if t.shape[0] == 27:\n",
    "        all_tensors.append(t)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "tensor_data = torch.cat(all_tensors, dim=0)\n",
    "tensor_data = np.repeat(tensor_data[..., np.newaxis], 3, -1).transpose(-1,-2).transpose(-2,-3)\n",
    "\n",
    "# tensor_data = tensor_data.transpose(-1,0).transpose(-1,-2)\n",
    "tensor_labels = torch.cat(all_labels).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb60fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3627, 3, 201, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data=rgb_data\n",
    "tensor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d14988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(tensor_data, tensor_labels)\n",
    "train_data, test_data = random_split(dataset, [3000, 627])\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14436516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # Define the layers of your CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(16 * 201 * 192, 31)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2367bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74be8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Compilation\n",
    "model = MyCNN(31)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b53dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b0681d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyCNN(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=31, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bccfa5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch 1/100, Validation Loss: 7.6264, Validation Accuracy: 0.0750\n",
      "epoch 1\n",
      "Epoch 2/100, Validation Loss: 2.6868, Validation Accuracy: 0.3349\n",
      "epoch 2\n",
      "Epoch 3/100, Validation Loss: 2.3940, Validation Accuracy: 0.3541\n",
      "epoch 3\n",
      "Epoch 4/100, Validation Loss: 1.6621, Validation Accuracy: 0.4769\n",
      "epoch 4\n",
      "Epoch 5/100, Validation Loss: 1.2855, Validation Accuracy: 0.5470\n",
      "epoch 5\n",
      "Epoch 6/100, Validation Loss: 1.1293, Validation Accuracy: 0.6093\n",
      "epoch 6\n",
      "Epoch 7/100, Validation Loss: 0.8178, Validation Accuracy: 0.6746\n",
      "epoch 7\n",
      "Epoch 8/100, Validation Loss: 0.9926, Validation Accuracy: 0.5726\n",
      "epoch 8\n",
      "Epoch 9/100, Validation Loss: 1.5253, Validation Accuracy: 0.6459\n",
      "epoch 9\n",
      "Epoch 10/100, Validation Loss: 0.8127, Validation Accuracy: 0.7018\n",
      "epoch 10\n",
      "Epoch 11/100, Validation Loss: 1.7683, Validation Accuracy: 0.6746\n",
      "epoch 11\n",
      "Epoch 12/100, Validation Loss: 1.6360, Validation Accuracy: 0.6443\n",
      "epoch 12\n",
      "Epoch 13/100, Validation Loss: 0.7579, Validation Accuracy: 0.6651\n",
      "epoch 13\n",
      "Epoch 14/100, Validation Loss: 0.8520, Validation Accuracy: 0.7145\n",
      "epoch 14\n",
      "Epoch 15/100, Validation Loss: 1.6689, Validation Accuracy: 0.6826\n",
      "epoch 15\n",
      "Epoch 16/100, Validation Loss: 0.2590, Validation Accuracy: 0.7273\n",
      "epoch 16\n",
      "Epoch 17/100, Validation Loss: 0.4003, Validation Accuracy: 0.7416\n",
      "epoch 17\n",
      "Epoch 18/100, Validation Loss: 0.8804, Validation Accuracy: 0.7113\n",
      "epoch 18\n",
      "Epoch 19/100, Validation Loss: 0.9097, Validation Accuracy: 0.7002\n",
      "epoch 19\n",
      "Epoch 20/100, Validation Loss: 2.1527, Validation Accuracy: 0.6029\n",
      "epoch 20\n",
      "Epoch 21/100, Validation Loss: 1.2729, Validation Accuracy: 0.6459\n",
      "epoch 21\n",
      "Epoch 22/100, Validation Loss: 1.9631, Validation Accuracy: 0.7560\n",
      "epoch 22\n",
      "Epoch 23/100, Validation Loss: 1.4346, Validation Accuracy: 0.7592\n",
      "epoch 23\n",
      "Epoch 24/100, Validation Loss: 1.8041, Validation Accuracy: 0.7544\n",
      "epoch 24\n",
      "Epoch 25/100, Validation Loss: 1.0264, Validation Accuracy: 0.7719\n",
      "epoch 25\n",
      "Epoch 26/100, Validation Loss: 1.4577, Validation Accuracy: 0.7576\n",
      "epoch 26\n",
      "Epoch 27/100, Validation Loss: 1.0804, Validation Accuracy: 0.7847\n",
      "epoch 27\n",
      "Epoch 28/100, Validation Loss: 0.5447, Validation Accuracy: 0.7799\n",
      "epoch 28\n",
      "Epoch 29/100, Validation Loss: 0.4611, Validation Accuracy: 0.7671\n",
      "epoch 29\n",
      "Epoch 30/100, Validation Loss: 0.5852, Validation Accuracy: 0.7863\n",
      "epoch 30\n",
      "Epoch 31/100, Validation Loss: 0.5808, Validation Accuracy: 0.7703\n",
      "epoch 31\n",
      "Epoch 32/100, Validation Loss: 2.4195, Validation Accuracy: 0.6108\n",
      "epoch 32\n",
      "Epoch 33/100, Validation Loss: 3.2721, Validation Accuracy: 0.4322\n",
      "epoch 33\n",
      "Epoch 34/100, Validation Loss: 1.7122, Validation Accuracy: 0.6986\n",
      "epoch 34\n",
      "Epoch 35/100, Validation Loss: 0.5104, Validation Accuracy: 0.6842\n",
      "epoch 35\n",
      "Epoch 36/100, Validation Loss: 1.3900, Validation Accuracy: 0.7927\n",
      "epoch 36\n",
      "Epoch 37/100, Validation Loss: 0.7182, Validation Accuracy: 0.7943\n",
      "epoch 37\n",
      "Epoch 38/100, Validation Loss: 0.0166, Validation Accuracy: 0.8150\n",
      "epoch 38\n",
      "Epoch 39/100, Validation Loss: 0.3442, Validation Accuracy: 0.8070\n",
      "epoch 39\n",
      "Epoch 40/100, Validation Loss: 0.8519, Validation Accuracy: 0.8262\n",
      "epoch 40\n",
      "Epoch 41/100, Validation Loss: 1.1698, Validation Accuracy: 0.8262\n",
      "epoch 41\n",
      "Epoch 42/100, Validation Loss: 0.9874, Validation Accuracy: 0.8341\n",
      "epoch 42\n",
      "Epoch 43/100, Validation Loss: 1.7058, Validation Accuracy: 0.8453\n",
      "epoch 43\n",
      "Epoch 44/100, Validation Loss: 0.1010, Validation Accuracy: 0.8357\n",
      "epoch 44\n",
      "Epoch 45/100, Validation Loss: 0.3351, Validation Accuracy: 0.8373\n",
      "epoch 45\n",
      "Epoch 46/100, Validation Loss: 0.8414, Validation Accuracy: 0.8453\n",
      "epoch 46\n",
      "Epoch 47/100, Validation Loss: 0.1284, Validation Accuracy: 0.8437\n",
      "epoch 47\n",
      "Epoch 48/100, Validation Loss: 1.1886, Validation Accuracy: 0.8485\n",
      "epoch 48\n",
      "Epoch 49/100, Validation Loss: 0.7116, Validation Accuracy: 0.8453\n",
      "epoch 49\n",
      "Epoch 50/100, Validation Loss: 1.3152, Validation Accuracy: 0.8469\n",
      "epoch 50\n",
      "Epoch 51/100, Validation Loss: 1.0308, Validation Accuracy: 0.8469\n",
      "epoch 51\n",
      "Epoch 52/100, Validation Loss: 0.8090, Validation Accuracy: 0.8293\n",
      "epoch 52\n",
      "Epoch 53/100, Validation Loss: 0.9216, Validation Accuracy: 0.8357\n",
      "epoch 53\n",
      "Epoch 54/100, Validation Loss: 0.6180, Validation Accuracy: 0.8309\n",
      "epoch 54\n",
      "Epoch 55/100, Validation Loss: 1.0380, Validation Accuracy: 0.8357\n",
      "epoch 55\n",
      "Epoch 56/100, Validation Loss: 0.2342, Validation Accuracy: 0.8405\n",
      "epoch 56\n",
      "Epoch 57/100, Validation Loss: 0.1980, Validation Accuracy: 0.8469\n",
      "epoch 57\n",
      "Epoch 58/100, Validation Loss: 0.5038, Validation Accuracy: 0.8389\n",
      "epoch 58\n",
      "Epoch 59/100, Validation Loss: 0.1947, Validation Accuracy: 0.8309\n",
      "epoch 59\n",
      "Epoch 60/100, Validation Loss: 0.1557, Validation Accuracy: 0.8421\n",
      "epoch 60\n",
      "Epoch 61/100, Validation Loss: 0.4108, Validation Accuracy: 0.8373\n",
      "epoch 61\n",
      "Epoch 62/100, Validation Loss: 0.2139, Validation Accuracy: 0.8533\n",
      "epoch 62\n",
      "Epoch 63/100, Validation Loss: 0.5756, Validation Accuracy: 0.8453\n",
      "epoch 63\n",
      "Epoch 64/100, Validation Loss: 1.1053, Validation Accuracy: 0.8437\n",
      "epoch 64\n",
      "Epoch 65/100, Validation Loss: 0.2479, Validation Accuracy: 0.8389\n",
      "epoch 65\n",
      "Epoch 66/100, Validation Loss: 0.1373, Validation Accuracy: 0.8501\n",
      "epoch 66\n",
      "Epoch 67/100, Validation Loss: 0.3568, Validation Accuracy: 0.8485\n",
      "epoch 67\n",
      "Epoch 68/100, Validation Loss: 0.3477, Validation Accuracy: 0.8469\n",
      "epoch 68\n",
      "Epoch 69/100, Validation Loss: 1.1178, Validation Accuracy: 0.8549\n",
      "epoch 69\n",
      "Epoch 70/100, Validation Loss: 0.5247, Validation Accuracy: 0.8501\n",
      "epoch 70\n",
      "Epoch 71/100, Validation Loss: 0.5583, Validation Accuracy: 0.8533\n",
      "epoch 71\n",
      "Epoch 72/100, Validation Loss: 0.2799, Validation Accuracy: 0.8501\n",
      "epoch 72\n",
      "Epoch 73/100, Validation Loss: 1.7936, Validation Accuracy: 0.8437\n",
      "epoch 73\n",
      "Epoch 74/100, Validation Loss: 0.1233, Validation Accuracy: 0.8485\n",
      "epoch 74\n",
      "Epoch 75/100, Validation Loss: 1.3445, Validation Accuracy: 0.8517\n",
      "epoch 75\n",
      "Epoch 76/100, Validation Loss: 0.6529, Validation Accuracy: 0.8485\n",
      "epoch 76\n",
      "Epoch 77/100, Validation Loss: 0.3960, Validation Accuracy: 0.8533\n",
      "epoch 77\n",
      "Epoch 78/100, Validation Loss: 0.5543, Validation Accuracy: 0.8437\n",
      "epoch 78\n",
      "Epoch 79/100, Validation Loss: 0.3832, Validation Accuracy: 0.8437\n",
      "epoch 79\n",
      "Epoch 80/100, Validation Loss: 1.7015, Validation Accuracy: 0.8565\n",
      "epoch 80\n",
      "Epoch 81/100, Validation Loss: 0.5641, Validation Accuracy: 0.8405\n",
      "epoch 81\n",
      "Epoch 82/100, Validation Loss: 0.4740, Validation Accuracy: 0.8485\n",
      "epoch 82\n",
      "Epoch 83/100, Validation Loss: 0.8355, Validation Accuracy: 0.8421\n",
      "epoch 83\n",
      "Epoch 84/100, Validation Loss: 1.1318, Validation Accuracy: 0.8437\n",
      "epoch 84\n",
      "Epoch 85/100, Validation Loss: 0.6472, Validation Accuracy: 0.8485\n",
      "epoch 85\n",
      "Epoch 86/100, Validation Loss: 0.3922, Validation Accuracy: 0.8405\n",
      "epoch 86\n",
      "Epoch 87/100, Validation Loss: 0.8700, Validation Accuracy: 0.8485\n",
      "epoch 87\n",
      "Epoch 88/100, Validation Loss: 0.1431, Validation Accuracy: 0.8485\n",
      "epoch 88\n",
      "Epoch 89/100, Validation Loss: 0.6066, Validation Accuracy: 0.8485\n",
      "epoch 89\n",
      "Epoch 90/100, Validation Loss: 0.2732, Validation Accuracy: 0.8549\n",
      "epoch 90\n",
      "Epoch 91/100, Validation Loss: 0.2243, Validation Accuracy: 0.8596\n",
      "epoch 91\n",
      "Epoch 92/100, Validation Loss: 0.4919, Validation Accuracy: 0.8501\n",
      "epoch 92\n",
      "Epoch 93/100, Validation Loss: 0.1511, Validation Accuracy: 0.8453\n",
      "epoch 93\n",
      "Epoch 94/100, Validation Loss: 0.6673, Validation Accuracy: 0.8469\n",
      "epoch 94\n",
      "Epoch 95/100, Validation Loss: 0.8837, Validation Accuracy: 0.8596\n",
      "epoch 95\n",
      "Epoch 96/100, Validation Loss: 0.0394, Validation Accuracy: 0.8501\n",
      "epoch 96\n",
      "Epoch 97/100, Validation Loss: 1.0259, Validation Accuracy: 0.8485\n",
      "epoch 97\n",
      "Epoch 98/100, Validation Loss: 0.7342, Validation Accuracy: 0.8533\n",
      "epoch 98\n",
      "Epoch 99/100, Validation Loss: 0.4940, Validation Accuracy: 0.8469\n",
      "epoch 99\n",
      "Epoch 100/100, Validation Loss: 0.1350, Validation Accuracy: 0.8517\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(f'epoch {epoch}')\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels= labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).to(device)  # Add a channel dimension to the input\n",
    "        loss = criterion(outputs, labels).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Step 6: Model Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cumulative_accuracy = torch.tensor([]).to(device)\n",
    "        for batch in test_dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            val_outputs = model(inputs).to(device)\n",
    "            val_loss = criterion(val_outputs, labels).to(device)\n",
    "            val_predictions = torch.argmax(val_outputs, dim=1).to(device)\n",
    "            val_accuracy = (val_predictions == labels).float().to(device)\n",
    "            cumulative_accuracy = torch.cat([cumulative_accuracy,val_accuracy], dim=0).to(device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {cumulative_accuracy.mean().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
