{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3546012b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.io as sio\n",
    "from characterDefinitions import getHandwritingCharacterDefinitions\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14aa745",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a6587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirs = ['t5.2019.05.08','t5.2019.11.25','t5.2019.12.09','t5.2019.12.11','t5.2019.12.18',\n",
    "            't5.2019.12.20','t5.2020.01.06','t5.2020.01.08','t5.2020.01.13','t5.2020.01.15']\n",
    "charDef = getHandwritingCharacterDefinitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e86edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = []\n",
    "all_labels = []\n",
    "for directory in dataDirs:\n",
    "    \n",
    "    mat = f'./Datasets/{directory}/singleLetters.mat'\n",
    "    data = sio.loadmat(mat)\n",
    "    ctr = 0\n",
    "    for letter in charDef['charList']:\n",
    "        t = torch.Tensor(data[f'neuralActivityCube_{letter}'])\n",
    "        qty = t.shape[0]\n",
    "        labels = torch.Tensor([ctr]*qty)\n",
    "        ctr += 1\n",
    "#         if t.shape[0] == 27:\n",
    "        all_tensors.append(t)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "tensor_data = torch.cat(all_tensors, dim=0)\n",
    "tensor_data = np.repeat(tensor_data[..., np.newaxis], 3, -1).transpose(-1,-2).transpose(-2,-3)\n",
    "\n",
    "# tensor_data = tensor_data.transpose(-1,0).transpose(-1,-2)\n",
    "tensor_labels = torch.cat(all_labels).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb60fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3627, 3, 201, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data=rgb_data\n",
    "tensor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d14988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(tensor_data, tensor_labels)\n",
    "train_data, test_data = random_split(dataset, [3000, 627])\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14436516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # Define the layers of your CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(16 * 201 * 192, 31)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2367bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74be8fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jcbolo/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/jcbolo/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Compilation\n",
    "model = MyCNN(31)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b53dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Add a channel dimension to the input\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Step 6: Model Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cumulative_accuracy = torch.tensor([])\n",
    "        for batch in test_dataloader:\n",
    "            inputs, labels = batch\n",
    "            val_outputs = model(inputs)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "            val_accuracy = (val_predictions == labels).float()\n",
    "            cumulative_accuracy = torch.cat([cumulative_accuracy,val_accuracy], dim=0)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {cumulative_accuracy.mean().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
